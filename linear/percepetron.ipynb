{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import *\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2. , 0. , 6.4, 0. , 0. , 1.7, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 3.1, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 2.2, 0. , 0. , 2.1, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 3.8, 0. , 5.5]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.csr_matrix(np.asarray([[2. , 0. , 6.4, 0. , 0. , 1.7, 0. ],\n",
    "       [0. , 0. , 0. , 0. , 3.1, 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 2.2, 0. , 0. , 2.1, 0. ],\n",
    "       [0. , 0. , 0. , 0. , 3.8, 0. , 5.5]])).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2. , 0. , 6.4, 0. , 0. , 1.7, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 3.1, 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 2.2, 0. , 0. , 2.1, 0. ],\n",
       "       [0. , 0. , 0. , 0. , 3.8, 0. , 5.5]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.sparse.csr_matrix(np.asarray([[2. , 0. , 6.4, 0. , 0. , 1.7, 0. ],\n",
    "       [0. , 0. , 0. , 0. , 3.1, 0. , 0. ],\n",
    "       [0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
    "       [0. , 0. , 2.2, 0. , 0. , 2.1, 0. ],\n",
    "       [0. , 0. , 0. , 0. , 3.8, 0. , 5.5]])).tocsr().toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category1 Category2  Target\n",
      "0         A         X       1\n",
      "1         B         Y       0\n",
      "2         A         X       1\n",
      "3         B         Y       0\n",
      "4         A         X       1\n",
      "5         A         Y       1\n",
      "6         B         X       0\n",
      "7         B         Y       0\n",
      "Encoded Training Data:\n",
      "   Category1  Category2  Target\n",
      "0        1.0   0.666667       1\n",
      "2        1.0   0.666667       1\n",
      "3        0.0   0.000000       0\n",
      "4        1.0   0.666667       1\n",
      "6        0.0   1.000000       0\n",
      "7        0.0   0.000000       0\n",
      "\n",
      "Encoded Test Data:\n",
      "   Category1  Category2  Target\n",
      "1        0.0        0.0       0\n",
      "5        1.0        0.0       1\n"
     ]
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample dataset (replace this with your own dataset)\n",
    "data = {\n",
    "    'Category1': ['A', 'B', 'A', 'B', 'A', 'A', 'B', 'B'],\n",
    "    'Category2': ['X', 'Y', 'X', 'Y', 'X', 'Y', 'X', 'Y'],\n",
    "    'Target': [1, 0, 1, 0, 1, 1, 0, 0]\n",
    "}\n",
    "print(pd.DataFrame(data))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Specify categorical columns for LOO encoding\n",
    "categorical_columns = ['Category1', 'Category2']\n",
    "\n",
    "# Initialize LOO encoder\n",
    "loo_encoder = ce.leave_one_out.LeaveOneOutEncoder(cols=categorical_columns)\n",
    "\n",
    "# Fit and transform on the training data\n",
    "train_encoded = loo_encoder.fit_transform(train_df, train_df['Target'])\n",
    "\n",
    "# Transform the test data using the encoder fitted on the training data\n",
    "test_encoded = loo_encoder.transform(test_df)\n",
    "\n",
    "# Display the results\n",
    "print(\"Encoded Training Data:\")\n",
    "print(train_encoded.sort_index())\n",
    "\n",
    "print(\"\\nEncoded Test Data:\")\n",
    "print(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
